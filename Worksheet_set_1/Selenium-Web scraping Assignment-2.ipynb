{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17e0d110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab828ac1",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10\n",
    "jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3dda5240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job-title</th>\n",
       "      <th>job-location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hiring -Data Analyst, Business Analyst, MIS An...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Analyst III</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Business Analyst/ Data Analyst- Capital Market...</td>\n",
       "      <td>Pune, Bangalore/Bengaluru</td>\n",
       "      <td>Genpact</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Customer Data Management Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Aspect</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Assistant/deputy Manager - Geo-spatial Data An...</td>\n",
       "      <td>Gurgaon/Gurugram, bangalore</td>\n",
       "      <td>Maruti Suzuki India</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Rapido</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...</td>\n",
       "      <td>SYREN TECHNOLOGIES PRIVATE LIMITED</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>4-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Openings For SQL Data Analyst</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru</td>\n",
       "      <td>StackNexus Technologies India Pvt. Ltd</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job-title  \\\n",
       "0  Hiring -Data Analyst, Business Analyst, MIS An...   \n",
       "1                            Senior Data Analyst III   \n",
       "2                                       Data Analyst   \n",
       "3  Business Analyst/ Data Analyst- Capital Market...   \n",
       "4                   Customer Data Management Analyst   \n",
       "5  Assistant/deputy Manager - Geo-spatial Data An...   \n",
       "6                                Senior Data Analyst   \n",
       "7                                Senior Data Analyst   \n",
       "8                                Senior Data Analyst   \n",
       "9                      Openings For SQL Data Analyst   \n",
       "\n",
       "                                        job-location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1                                Bengaluru/Bangalore   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                          Pune, Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                        Gurgaon/Gurugram, bangalore   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7  Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...   \n",
       "8                                Bengaluru/Bangalore   \n",
       "9        Hyderabad/Secunderabad, Bangalore/Bengaluru   \n",
       "\n",
       "                              company_name experience_required  \n",
       "0                                 Flipkart             1-6 Yrs  \n",
       "1                                 Flipkart             2-4 Yrs  \n",
       "2  GlaxoSmithKline Pharmaceuticals Limited             3-8 Yrs  \n",
       "3                                  Genpact            7-12 Yrs  \n",
       "4                                   Aspect             0-2 Yrs  \n",
       "5                      Maruti Suzuki India             3-5 Yrs  \n",
       "6                                   Rapido             1-6 Yrs  \n",
       "7       SYREN TECHNOLOGIES PRIVATE LIMITED            5-10 Yrs  \n",
       "8                                 Flipkart             4-5 Yrs  \n",
       "9   StackNexus Technologies India Pvt. Ltd             3-6 Yrs  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the webpage https://www.naukri.com/\n",
    "def get_naukri_info(url):\n",
    "    #intiating the browser\n",
    "    driver=webdriver.Chrome('C:/Users/yn/Desktop/Yuvi/DataTrained/seleniumWebdriver/chromedriver.exe')\n",
    "    #loading the given url\n",
    "    driver.get(url)\n",
    "    try:\n",
    "        #Enter “Data Analyst” in “Skill, Designations, Companies” field \n",
    "        send_title=driver.find_element_by_xpath('//input[@placeholder=\"Skills, Designations, Companies\"]').send_keys('Data Analyst')\n",
    "        #Enter “Bangalore” in “enter the location” field\n",
    "        send_location=driver.find_element_by_name('location').send_keys('Bangalore')\n",
    "        #Then click the search button.\n",
    "        click_search=driver.find_element_by_xpath('//div[@class=\"search-btn\"]/button').click()\n",
    "        driver.implicitly_wait(30)\n",
    "        # collect title info \n",
    "        job_title=[title.text for title in driver.find_elements_by_xpath('//div[@class=\"info fleft\"]/a')]\n",
    "        # collect location name\n",
    "        job_location=[loc.text for loc in driver.find_elements_by_xpath('//li[contains(@class,\"location\")]/span[1]')]\n",
    "        # collect company name\n",
    "        company_name=[comp.text for comp in driver.find_elements_by_xpath('//div[contains(@class,\"companyInfo\")]/a[1]')]\n",
    "        # collect experience required\n",
    "        experience_required=[exp.text for exp in driver.find_elements_by_xpath('//i[contains(@class,\"naukicon-experience\")]/following-sibling::span[1]')]\n",
    "        #Create Dataframe using pandas\n",
    "        df=pd.DataFrame({'job-title':job_title[:10],'job-location':job_location[:10],'company_name':company_name[:10],'experience_required':experience_required[:10]})\n",
    "        return df\n",
    "    finally:\n",
    "        #closing the browser window\n",
    "        driver.close()\n",
    "        #Quiting the .exe fill which is triggered to initiate the browser\n",
    "        driver.quit()\n",
    "\n",
    "get_naukri_info('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf6e451",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/ \n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29a03767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job-title</th>\n",
       "      <th>job-location</th>\n",
       "      <th>company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Snaphunt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science - Senior Data Scientist</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "      <td>Paytm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Ally-Executive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Visa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - Credit Risk</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Scienaptic Systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lead/Senior Data Scientist (NLP)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Samya.AI A FRACTAL Entity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Truecaller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Slice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Advanced Analytics Expert - Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Bangalore</td>\n",
       "      <td>Hewlett-Packard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist 2</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>ANI Technologies Pvt. Ltd.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    job-title                    job-location  \\\n",
       "0                              Data Scientist             Bangalore/Bengaluru   \n",
       "1        Data Science - Senior Data Scientist      Noida, Bangalore/Bengaluru   \n",
       "2                       Senior Data Scientist             Bangalore/Bengaluru   \n",
       "3                       Senior Data Scientist             Bangalore/Bengaluru   \n",
       "4                Data Scientist - Credit Risk             Bangalore/Bengaluru   \n",
       "5            Lead/Senior Data Scientist (NLP)             Bangalore/Bengaluru   \n",
       "6                              Data Scientist             Bangalore/Bengaluru   \n",
       "7                              Data Scientist             Bangalore/Bengaluru   \n",
       "8  Advanced Analytics Expert - Data Scientist  Bangalore/Bengaluru, Bangalore   \n",
       "9                            Data Scientist 2             Bangalore/Bengaluru   \n",
       "\n",
       "                 company_name  \n",
       "0                    Snaphunt  \n",
       "1                       Paytm  \n",
       "2              Ally-Executive  \n",
       "3                        Visa  \n",
       "4          Scienaptic Systems  \n",
       "5   Samya.AI A FRACTAL Entity  \n",
       "6                  Truecaller  \n",
       "7                       Slice  \n",
       "8             Hewlett-Packard  \n",
       "9  ANI Technologies Pvt. Ltd.  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the webpage https://www.naukri.com/\n",
    "def get_naukri_info_data_science(url):\n",
    "    #intiating the browser\n",
    "    driver=webdriver.Chrome('C:/Users/yn/Desktop/Yuvi/DataTrained/seleniumWebdriver/chromedriver.exe')\n",
    "    #loading the given url\n",
    "    driver.get(url)\n",
    "    try:\n",
    "        #Enter “Data Analyst” in “Skill, Designations, Companies” field \n",
    "        send_title=driver.find_element_by_xpath('//input[@placeholder=\"Skills, Designations, Companies\"]').send_keys('Data Scientist')\n",
    "        #Enter “Bangalore” in “enter the location” field\n",
    "        send_location=driver.find_element_by_name('location').send_keys('Bangalore')\n",
    "        #Then click the search button.\n",
    "        click_search=driver.find_element_by_xpath('//div[@class=\"search-btn\"]/button').click()\n",
    "        #wait for 3 seconds after clicking on search\n",
    "        driver.implicitly_wait(30)\n",
    "        # collect title info \n",
    "        job_title=[title.text for title in driver.find_elements_by_xpath('//div[@class=\"info fleft\"]/a')]  \n",
    "        # collect location name\n",
    "        job_location=[loc.text for loc in driver.find_elements_by_xpath('//li[contains(@class,\"location\")]/span[1]')]   \n",
    "        # collect company name\n",
    "        company_name=[comp.text for comp in driver.find_elements_by_xpath('//div[contains(@class,\"companyInfo\")]/a[1]')]\n",
    "        #Create Dataframe using pandas\n",
    "        df=pd.DataFrame({'job-title':job_title[:10],'job-location':job_location[:10],'company_name':company_name[:10]})\n",
    "        return df\n",
    "    finally:\n",
    "        #closing the browser window\n",
    "        driver.close()\n",
    "        #Quiting the .exe fill which is triggered to initiate the browser\n",
    "        driver.quit()\n",
    "        \n",
    "get_naukri_info_data_science('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5462e794",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the webpage as shown below: \n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR” The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66639d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job-title</th>\n",
       "      <th>job-location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science - Senior Data Scientist</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "      <td>Paytm</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Pune, Bangalore/Bengaluru, Delhi / NCR</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Chennai...</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist: Advanced Analytics</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Genpact</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Manager - Forecasting data scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Genpact</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida, New Delhi, Faridabad, Gurgaon/Gurugram,...</td>\n",
       "      <td>LG Electronics India Pvt. Ltd.</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist | Senior Data Scientist</td>\n",
       "      <td>Delhi / NCR, DelhiNCR</td>\n",
       "      <td>4bell Technology</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist/Senior Scientist - Python/Spark...</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Connexions</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Talent Integrators</td>\n",
       "      <td>8-12 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job-title  \\\n",
       "0               Data Science - Senior Data Scientist   \n",
       "1                              Senior Data Scientist   \n",
       "2                              Senior Data Scientist   \n",
       "3                 Data Scientist: Advanced Analytics   \n",
       "4                                 Sr. Data Scientist   \n",
       "5        Senior Manager - Forecasting data scientist   \n",
       "6                                     Data Scientist   \n",
       "7             Data Scientist | Senior Data Scientist   \n",
       "8  Data Scientist/Senior Scientist - Python/Spark...   \n",
       "9                                  Sr Data Scientist   \n",
       "\n",
       "                                        job-location  \\\n",
       "0                         Noida, Bangalore/Bengaluru   \n",
       "1             Pune, Bangalore/Bengaluru, Delhi / NCR   \n",
       "2  Kolkata, Hyderabad/Secunderabad, Pune, Chennai...   \n",
       "3                                        Delhi / NCR   \n",
       "4                                   Gurgaon/Gurugram   \n",
       "5                                   Gurgaon/Gurugram   \n",
       "6  Noida, New Delhi, Faridabad, Gurgaon/Gurugram,...   \n",
       "7                              Delhi / NCR, DelhiNCR   \n",
       "8                                   Gurgaon/Gurugram   \n",
       "9                                   Gurgaon/Gurugram   \n",
       "\n",
       "                     company_name experience_required  \n",
       "0                           Paytm             2-4 Yrs  \n",
       "1                           Wipro             4-9 Yrs  \n",
       "2                           Wipro            5-10 Yrs  \n",
       "3          IBM India Pvt. Limited            5-10 Yrs  \n",
       "4                         Genpact             4-9 Yrs  \n",
       "5                         Genpact            5-10 Yrs  \n",
       "6  LG Electronics India Pvt. Ltd.             0-2 Yrs  \n",
       "7                4bell Technology            6-11 Yrs  \n",
       "8                      Connexions             2-6 Yrs  \n",
       "9              Talent Integrators            8-12 Yrs  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the webpage https://www.naukri.com/\n",
    "def get_naukri_info_apply_filter(url):\n",
    "    #intiating the browser\n",
    "    driver=webdriver.Chrome('C:/Users/yn/Desktop/Yuvi/DataTrained/seleniumWebdriver/chromedriver.exe')\n",
    "    #loading the given url\n",
    "    driver.get(url)\n",
    "    try:\n",
    "        #Enter “Data Analyst” in “Skill, Designations, Companies” field \n",
    "        send_title=driver.find_element_by_xpath('//input[@placeholder=\"Skills, Designations, Companies\"]').send_keys('Data Scientist')   \n",
    "        #Then click the search button.\n",
    "        click_search=driver.find_element_by_xpath('//div[@class=\"search-btn\"]/button').click()\n",
    "        #wait for 3 seconds after clicking on search\n",
    "        driver.implicitly_wait(30)\n",
    "\n",
    "        #select location filter\n",
    "        if(not(driver.find_element_by_xpath('//label[@for=\"chk-Delhi / NCR-cityTypeGid-\"]/i').is_selected())):\n",
    "            driver.find_element_by_xpath('//label[@for=\"chk-Delhi / NCR-cityTypeGid-\"]/i').click()\n",
    "        #select salary filter\n",
    "        if(not(driver.find_element_by_xpath('//label[@for=\"chk-3-6 Lakhs-ctcFilter-\"]/i').is_selected())):\n",
    "            driver.find_element_by_xpath('//label[@for=\"chk-3-6 Lakhs-ctcFilter-\"]/i').click()\n",
    "\n",
    "        #wait for 3 seconds after selecting filters    \n",
    "        driver.implicitly_wait(30)\n",
    "\n",
    "        # collect title info \n",
    "        job_title=[title.text for title in driver.find_elements_by_xpath('//div[@class=\"info fleft\"]/a')]  \n",
    "        # collect location name\n",
    "        job_location=[loc.text for loc in driver.find_elements_by_xpath('//li[contains(@class,\"location\")]/span[1]')]   \n",
    "        # collect company name\n",
    "        company_name=[comp.text for comp in driver.find_elements_by_xpath('//div[contains(@class,\"companyInfo\")]/a[1]')]\n",
    "        # collect experience required\n",
    "        experience_required=[exp.text for exp in driver.find_elements_by_xpath('//i[contains(@class,\"naukicon-experience\")]/following-sibling::span[1]')]      \n",
    "        #Create Dataframe using pandas\n",
    "        df=pd.DataFrame({'job-title':job_title[:10],'job-location':job_location[:10],'company_name':company_name[:10],'experience_required':experience_required[:10]})\n",
    "        return df\n",
    "    finally:\n",
    "        #closing the browser window\n",
    "        driver.close()\n",
    "        #Quiting the .exe fill which is triggered to initiate the browser\n",
    "        driver.quit()\n",
    "        \n",
    "\n",
    "get_naukri_info_apply_filter('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc337860",
   "metadata": {},
   "source": [
    "Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "The attributes which you have to scrape is ticked marked in the below image. \n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and\n",
    "click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the\n",
    "required data as usual. \n",
    "4. After scraping data from the first page, go to the “Next” Button at the bottom of the page , then\n",
    "click on it.\n",
    "5. Now scrape data from this page as usual\n",
    "6. Repeat this until you get data for 100 sunglasses.\n",
    "Note: That all of the above steps have to be done by coding only and not manually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "534f7ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Offer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kanishka</td>\n",
       "      <td>Others Round Sunglasses (55)</td>\n",
       "      <td>₹151</td>\n",
       "      <td>84% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Polarized, UV Protection Round Sunglasses (53)</td>\n",
       "      <td>₹664</td>\n",
       "      <td>66% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (56)</td>\n",
       "      <td>₹188</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹248</td>\n",
       "      <td>90% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹187</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Polarized, UV Protection Round Sunglasses (53)</td>\n",
       "      <td>₹664</td>\n",
       "      <td>66% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>New Specs</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹188</td>\n",
       "      <td>87% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection, Gradient Butterfly Sunglasses (57)</td>\n",
       "      <td>₹664</td>\n",
       "      <td>66% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (53)</td>\n",
       "      <td>₹319</td>\n",
       "      <td>90% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Polarized, UV Protection Aviator Sunglasses (58)</td>\n",
       "      <td>₹759</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Brand                                Product Description Price  \\\n",
       "0    Kanishka                       Others Round Sunglasses (55)  ₹151   \n",
       "1   ROYAL SON     Polarized, UV Protection Round Sunglasses (53)  ₹664   \n",
       "2        SRPM             UV Protection Wayfarer Sunglasses (56)  ₹188   \n",
       "3   Elligator                UV Protection Round Sunglasses (54)  ₹248   \n",
       "4      PIRASO              UV Protection Aviator Sunglasses (54)  ₹187   \n",
       "..        ...                                                ...   ...   \n",
       "95  ROYAL SON     Polarized, UV Protection Round Sunglasses (53)  ₹664   \n",
       "96  New Specs   UV Protection Rectangular Sunglasses (Free Size)  ₹188   \n",
       "97  ROYAL SON  UV Protection, Gradient Butterfly Sunglasses (57)  ₹664   \n",
       "98  Elligator             UV Protection Wayfarer Sunglasses (53)  ₹319   \n",
       "99  ROYAL SON   Polarized, UV Protection Aviator Sunglasses (58)  ₹759   \n",
       "\n",
       "      Offer  \n",
       "0   84% off  \n",
       "1   66% off  \n",
       "2   85% off  \n",
       "3   90% off  \n",
       "4   88% off  \n",
       "..      ...  \n",
       "95  66% off  \n",
       "96  87% off  \n",
       "97  66% off  \n",
       "98  90% off  \n",
       "99  62% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_sunglass_flipkart(url):\n",
    "    #intiating the browser\n",
    "    driver=webdriver.Chrome('C:/Users/yn/Desktop/Yuvi/DataTrained/seleniumWebdriver/chromedriver.exe')\n",
    "    #loading the given url\n",
    "    driver.get(url)\n",
    "    brand_list=[]\n",
    "    prod_desc=[]\n",
    "    price_list=[]\n",
    "    offer_list=[]\n",
    "    try:\n",
    "        #Close login window before searching for product\n",
    "        close_login_page=driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]').click()\n",
    "        #Enter “sunglasses” in “earch for products, brands and more” field \n",
    "        send_product_name=driver.find_element_by_xpath('//input[@title=\"Search for products, brands and more\"]').send_keys('sunglasses')   \n",
    "        #Then click the search button.\n",
    "        click_search=driver.find_element_by_xpath('//button[@type=\"submit\"]').click()\n",
    "        #wait for 3 seconds after clicking on search\n",
    "        driver.implicitly_wait(30)\n",
    "        while(len(brand_list)<=100):\n",
    "            #refresh the webpage as we get stale elements\n",
    "            driver.refresh()\n",
    "            # collect title info \n",
    "            for brand in driver.find_elements_by_xpath('//div[contains(@class,\"1xHGtK _373qXS\")]//div[@class=\"_2WkVRV\"]'):\n",
    "                brand_list.append(brand.text)\n",
    "       \n",
    "            # collect location name\n",
    "            for desc in driver.find_elements_by_xpath('//div[contains(@class,\"1xHGtK _373qXS\")]//div[@class=\"_2WkVRV\"]/following-sibling::a[1]'):\n",
    "                prod_desc.append(desc.text)\n",
    "          \n",
    "            # collect company name\n",
    "            for price in driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]'):\n",
    "                price_list.append(price.text)\n",
    "          \n",
    "            # collect experience required\n",
    "            for offer in driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]/span'):\n",
    "                offer_list.append(offer.text)\n",
    "                \n",
    "            #click on next page\n",
    "            driver.find_element_by_xpath('//a[.=\"Next\"]').click()\n",
    "            \n",
    "            \n",
    "        #Create Dataframe using pandas\n",
    "        df=pd.DataFrame({'Brand':brand_list[:100],'Product Description':prod_desc[:100],'Price':price_list[:100],'Offer':offer_list[:100]})\n",
    "        return df\n",
    "    finally:\n",
    "        #closing the browser window\n",
    "        driver.close()\n",
    "        #Quiting the .exe fill which is triggered to initiate the browser\n",
    "        driver.quit()\n",
    "        \n",
    "get_sunglass_flipkart('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e00907",
   "metadata": {},
   "source": [
    "Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link:\n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb-includes- earpods-poweradapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC\n",
    "TSVZAXUHGREPBFGI&marketplace. When you will open the above link you will reach to the below shown webpage . \n",
    "As shown in the above page you have to scrape the tick marked attributes. These are:\n",
    "1. Rating\n",
    "2. Review_summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100 reviews.\n",
    "Note: All the steps required during scraping should be done through code only and not manually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e1919b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>I use a Note10+ and have been using both iOS a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>3</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>The phone is completely good\\nAs far as camera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Decent product</td>\n",
       "      <td>Everything u ll like it when u use this iPhone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>Can’t beat the software and hardware integrati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Does the job</td>\n",
       "      <td>phone is good but in display is 720p lcd in th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating       Review Summary  \\\n",
       "0       5            Brilliant   \n",
       "1       5       Simply awesome   \n",
       "2       5  Best in the market!   \n",
       "3       5     Perfect product!   \n",
       "4       5    Worth every penny   \n",
       "..    ...                  ...   \n",
       "95      5    Terrific purchase   \n",
       "96      3              Awesome   \n",
       "97      5       Decent product   \n",
       "98      5              Awesome   \n",
       "99      5         Does the job   \n",
       "\n",
       "                                          Full Review  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Really satisfied with the Product I received.....  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   Amazing phone with great cameras and better ba...  \n",
       "4   Previously I was using one plus 3t it was a gr...  \n",
       "..                                                ...  \n",
       "95  I use a Note10+ and have been using both iOS a...  \n",
       "96  The phone is completely good\\nAs far as camera...  \n",
       "97  Everything u ll like it when u use this iPhone...  \n",
       "98  Can’t beat the software and hardware integrati...  \n",
       "99  phone is good but in display is 720p lcd in th...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_iphone_review_flipkart(url):\n",
    "    #intiating the browser\n",
    "    driver=webdriver.Chrome('C:/Users/yn/Desktop/Yuvi/DataTrained/seleniumWebdriver/chromedriver.exe')\n",
    "    #loading the given url\n",
    "    driver.get(url)\n",
    "    \n",
    "    rating_list=[]   \n",
    "    review_sum_list=[]    \n",
    "    full_review_list=[]\n",
    "    \n",
    "    try:\n",
    "        #Click on all reviews to load all the reviews\n",
    "        click_all_reviews=driver.find_element_by_xpath('//span[contains(.,\"reviews\") and contains(.,\"All\")]/ancestor::a[1]').click()\n",
    "        #wait for 3 seconds after clicking on search\n",
    "        driver.implicitly_wait(10)\n",
    "        while(len(rating_list)<=100):\n",
    "            #refresh the webpage as we get stale elements\n",
    "            driver.refresh()\n",
    "            # collect title info \n",
    "            for rating in driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]'):\n",
    "                rating_list.append(rating.text)\n",
    "            \n",
    "            # collect location name\n",
    "            for review in driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]'):\n",
    "                review_sum_list.append(review.text)\n",
    "           \n",
    "            # collect company name\n",
    "            for full_review in driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]/div'):\n",
    "                full_review_list.append(full_review.text)\n",
    "           \n",
    "            #click on next page\n",
    "            click_btn=driver.find_element_by_xpath('//a[span[.=\"Next\"]]')\n",
    "            driver.execute_script('arguments[0].click();',click_btn)\n",
    "            driver.implicitly_wait(10)                 \n",
    "            \n",
    "        #Create Dataframe using pandas\n",
    "        df=pd.DataFrame({'Rating':rating_list[:100],'Review Summary':review_sum_list[:100],'Full Review':full_review_list[:100]})\n",
    "        return df\n",
    "    finally:\n",
    "        #closing the browser window\n",
    "        driver.close()\n",
    "        #Quiting the .exe fill which is triggered to initiate the browser\n",
    "        driver.quit()\n",
    "        \n",
    "get_iphone_review_flipkart('https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-%20earpods-poweradapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC%20TSVZAXUHGREPBFGI&marketplace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbc4389",
   "metadata": {},
   "source": [
    "Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the\n",
    "search field.\n",
    "You have to scrape 4 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "As shown in the below image, you have to scrape the tick marked attributes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d907d8fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Offer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Casual Shoes For Men Combo Pack Of 2 Sneakers ...</td>\n",
       "      <td>₹535</td>\n",
       "      <td>46% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LEE COOPER</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹1,484</td>\n",
       "      <td>45% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Modern Trendy Sneakers Shoes Sneakers For Men</td>\n",
       "      <td>₹299</td>\n",
       "      <td>76% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>URBANBOX</td>\n",
       "      <td>Sneakers Sneakers For Men</td>\n",
       "      <td>₹247</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Sports Running Shoes Sneakers For Men</td>\n",
       "      <td>₹299</td>\n",
       "      <td>40% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>EEKEN</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹879</td>\n",
       "      <td>45% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Zsyto</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹398</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Xtoon</td>\n",
       "      <td>white Casual shoes,Sneakers for men's Sneakers...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>66% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Perfect &amp; Affordable Combo Pack of 02 Pairs Sn...</td>\n",
       "      <td>₹536</td>\n",
       "      <td>58% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>HRX by Hrithik Roshan</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹1,599</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Brand                                Product Description  \\\n",
       "0                   BIRDE  Casual Shoes For Men Combo Pack Of 2 Sneakers ...   \n",
       "1              LEE COOPER                                   Sneakers For Men   \n",
       "2                  BRUTON      Modern Trendy Sneakers Shoes Sneakers For Men   \n",
       "3                URBANBOX                          Sneakers Sneakers For Men   \n",
       "4                   BIRDE              Sports Running Shoes Sneakers For Men   \n",
       "..                    ...                                                ...   \n",
       "95                  EEKEN                                   Sneakers For Men   \n",
       "96                  Zsyto                                   Sneakers For Men   \n",
       "97                  Xtoon  white Casual shoes,Sneakers for men's Sneakers...   \n",
       "98                 Chevit  Perfect & Affordable Combo Pack of 02 Pairs Sn...   \n",
       "99  HRX by Hrithik Roshan                                   Sneakers For Men   \n",
       "\n",
       "     Price    Offer  \n",
       "0     ₹535  46% off  \n",
       "1   ₹1,484  45% off  \n",
       "2     ₹299  76% off  \n",
       "3     ₹247  75% off  \n",
       "4     ₹299  40% off  \n",
       "..     ...      ...  \n",
       "95    ₹879  45% off  \n",
       "96    ₹398  60% off  \n",
       "97    ₹499  66% off  \n",
       "98    ₹536  58% off  \n",
       "99  ₹1,599  60% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_sneakers_flipkart(url):\n",
    "    #intiating the browser\n",
    "    driver=webdriver.Chrome('C:/Users/yn/Desktop/Yuvi/DataTrained/seleniumWebdriver/chromedriver.exe')\n",
    "    #loading the given url\n",
    "    driver.get(url)\n",
    "    brand_list=[]\n",
    "    prod_desc=[]\n",
    "    price_list=[]\n",
    "    offer_list=[]\n",
    "    try:\n",
    "        #Close login window before searching for product\n",
    "        close_login_page=driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]').click()\n",
    "        #Enter “sunglasses” in “earch for products, brands and more” field \n",
    "        send_product_name=driver.find_element_by_xpath('//input[@title=\"Search for products, brands and more\"]').send_keys('sneakers')   \n",
    "        #Then click the search button.\n",
    "        click_search=driver.find_element_by_xpath('//button[@type=\"submit\"]').click()\n",
    "        #wait for 3 seconds after clicking on search\n",
    "        driver.implicitly_wait(3)\n",
    "        while(len(brand_list)<=100):\n",
    "            #refresh the webpage as we get stale elements\n",
    "            driver.refresh()\n",
    "            # collect title info \n",
    "            for brand in driver.find_elements_by_xpath('//div[contains(@class,\"1xHGtK _373qXS\")]//div[@class=\"_2WkVRV\"]'):\n",
    "                brand_list.append(brand.text)\n",
    "       \n",
    "            # collect location name\n",
    "            for desc in driver.find_elements_by_xpath('//div[contains(@class,\"1xHGtK _373qXS\")]//div[@class=\"_2WkVRV\"]/following-sibling::a[1]'):\n",
    "                prod_desc.append(desc.text)\n",
    "          \n",
    "            # collect company name\n",
    "            for price in driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]'):\n",
    "                price_list.append(price.text)\n",
    "          \n",
    "            # collect experience required\n",
    "            for offer in driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]/span'):\n",
    "                offer_list.append(offer.text)\n",
    "                \n",
    "            #click on next page\n",
    "            driver.find_element_by_xpath('//a[.=\"Next\"]').click()\n",
    "            \n",
    "            \n",
    "        #Create Dataframe using pandas\n",
    "        df=pd.DataFrame({'Brand':brand_list[:100],'Product Description':prod_desc[:100],'Price':price_list[:100],'Offer':offer_list[:100]})\n",
    "        return df\n",
    "    finally:\n",
    "        #closing the browser window\n",
    "        driver.close()\n",
    "        #Quiting the .exe fill which is triggered to initiate the browser\n",
    "        driver.quit()\n",
    "        \n",
    "get_sneakers_flipkart('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1aab8bb",
   "metadata": {},
   "source": [
    "Q7: Go to the link - https://www.myntra.com/shoes\n",
    "Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”, as shown in the below image. \n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe\n",
    "description, price of the shoe as shown in the below image\n",
    "Note: Applying the filter and scraping the data, everything should be done through code only and there\n",
    "should not be any manual step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7188f1c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASICS</td>\n",
       "      <td>Men GEL-KAYANO 27 Shoes</td>\n",
       "      <td>Rs. 10499Rs. 14999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Puma</td>\n",
       "      <td></td>\n",
       "      <td>Rs. 6499Rs. 12999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men Textured Sneakers</td>\n",
       "      <td>Rs. 6999Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Men Solid Leather Formal Slip-Ons</td>\n",
       "      <td>Rs. 8099Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Deviate Nitro Running Shoe</td>\n",
       "      <td>Rs. 9749Rs. 14999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Leather Block Peep Toes</td>\n",
       "      <td>Rs. 9450Rs. 10500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Women Leather Sneakers</td>\n",
       "      <td>Rs. 7900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>DAVINCHI</td>\n",
       "      <td>Men Solid Formal Leather Slip-On Shoes</td>\n",
       "      <td>Rs. 6990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Women Solid Leather Ballerinas</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Cole Haan</td>\n",
       "      <td>Women Sneakers</td>\n",
       "      <td>Rs. 6499Rs. 12999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brand                     Product Description               Price\n",
       "0          ASICS                 Men GEL-KAYANO 27 Shoes  Rs. 10499Rs. 14999\n",
       "1           Puma                                           Rs. 6499Rs. 12999\n",
       "2           ALDO                   Men Textured Sneakers    Rs. 6999Rs. 9999\n",
       "3   Hush Puppies       Men Solid Leather Formal Slip-Ons    Rs. 8099Rs. 8999\n",
       "4           Puma          Men Deviate Nitro Running Shoe   Rs. 9749Rs. 14999\n",
       "..           ...                                     ...                 ...\n",
       "95       Saint G                 Leather Block Peep Toes   Rs. 9450Rs. 10500\n",
       "96       Saint G                  Women Leather Sneakers            Rs. 7900\n",
       "97      DAVINCHI  Men Solid Formal Leather Slip-On Shoes            Rs. 6990\n",
       "98          Geox          Women Solid Leather Ballerinas            Rs. 8999\n",
       "99     Cole Haan                          Women Sneakers   Rs. 6499Rs. 12999\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_shoes_myntra(url):\n",
    "    #intiating the browser\n",
    "    driver=webdriver.Chrome('C:/Users/yn/Desktop/Yuvi/DataTrained/seleniumWebdriver/chromedriver.exe')\n",
    "    #loading the given url\n",
    "    driver.get(url)\n",
    "    brand_list=[]\n",
    "    prod_desc=[]\n",
    "    price_list=[]\n",
    "    try:\n",
    "        #select color filter    \n",
    "        driver.find_element_by_xpath('//span[@data-colorhex=\"black\"]/following-sibling::div[@class=\"common-checkboxIndicator\"]').click()\n",
    "        #wait for 3 seconds after clicking on search\n",
    "        driver.implicitly_wait(10)\n",
    "        driver.refresh()\n",
    "        #select price filter    \n",
    "        driver.find_element_by_xpath('//ul[@class=\"price-list\"]/li[2]//div[@class=\"common-checkboxIndicator\"]').click()  \n",
    "        #wait for 3 seconds after clicking on search\n",
    "        driver.implicitly_wait(10)\n",
    "        \n",
    "        while(len(brand_list)<=100):\n",
    "            #refresh the webpage as we get stale elements\n",
    "            driver.refresh()\n",
    "            # collect brand info \n",
    "            for brand in driver.find_elements_by_xpath('//h3[@class=\"product-brand\"]'):\n",
    "                brand_list.append(brand.text)\n",
    "       \n",
    "            # collect prod description name\n",
    "            for desc in driver.find_elements_by_xpath('//h4[@class=\"product-product\"]'):\n",
    "                prod_desc.append(desc.text)\n",
    "          \n",
    "            # collect price \n",
    "            for price in driver.find_elements_by_xpath('//div[@class=\"product-price\"]/span[1]'):\n",
    "                price_list.append(price.text)\n",
    "                         \n",
    "            #click on next page\n",
    "            driver.find_element_by_xpath('//a[@rel=\"next\"]').click()\n",
    "            \n",
    "            \n",
    "        #Create Dataframe using pandas\n",
    "        df=pd.DataFrame({'Brand':brand_list[:100],'Product Description':prod_desc[:100],'Price':price_list[:100]})\n",
    "        return df\n",
    "    finally:\n",
    "        #closing the browser window\n",
    "        driver.close()\n",
    "        #Quiting the .exe fill which is triggered to initiate the browser\n",
    "        driver.quit()\n",
    "        \n",
    "get_shoes_myntra('https://www.myntra.com/shoes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbab0f6",
   "metadata": {},
   "source": [
    "Q8: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” as shown in the below image:\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price\n",
    "As shown in the below image as the tick marked attributes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "890617f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lenovo ThinkBook Yoga 14s Intel Core i7 11th G...</td>\n",
       "      <td>3.5 out of 5 stars</td>\n",
       "      <td>₹89,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fujitsu UH-X 11th Gen Intel i7 Core 13.3 inche...</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>₹92,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mi Notebook Pro QHD+ IPS Anti Glare Display In...</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>₹73,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i7-1...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>₹52,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dell 15 (2021) i7-10870H Gaming Laptop, 16GB D...</td>\n",
       "      <td>3.8 out of 5 stars</td>\n",
       "      <td>₹95,290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lenovo Yoga 7 11th Gen Intel Core i7 14\" Full ...</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>₹97,505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HP Pavilion (2021) Intel 11th Gen Core i7 14 i...</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>₹84,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>₹85,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mi Notebook Ultra 3.2K resolution display Inte...</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>₹77,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HP Pavilion 13, 11th Gen Intel Core i7, 13.3-i...</td>\n",
       "      <td>4.6 out of 5 stars</td>\n",
       "      <td>₹87,800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title              Rating  \\\n",
       "0  Lenovo ThinkBook Yoga 14s Intel Core i7 11th G...  3.5 out of 5 stars   \n",
       "1  Fujitsu UH-X 11th Gen Intel i7 Core 13.3 inche...  4.3 out of 5 stars   \n",
       "2  Mi Notebook Pro QHD+ IPS Anti Glare Display In...  4.3 out of 5 stars   \n",
       "3  Mi Notebook Horizon Edition 14 Intel Core i7-1...  4.2 out of 5 stars   \n",
       "4  Dell 15 (2021) i7-10870H Gaming Laptop, 16GB D...  3.8 out of 5 stars   \n",
       "5  Lenovo Yoga 7 11th Gen Intel Core i7 14\" Full ...  4.3 out of 5 stars   \n",
       "6  HP Pavilion (2021) Intel 11th Gen Core i7 14 i...  4.3 out of 5 stars   \n",
       "7  Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....  4.3 out of 5 stars   \n",
       "8  Mi Notebook Ultra 3.2K resolution display Inte...  4.3 out of 5 stars   \n",
       "9  HP Pavilion 13, 11th Gen Intel Core i7, 13.3-i...  4.6 out of 5 stars   \n",
       "\n",
       "     Price  \n",
       "0  ₹89,990  \n",
       "1  ₹92,990  \n",
       "2  ₹73,999  \n",
       "3  ₹52,999  \n",
       "4  ₹95,290  \n",
       "5  ₹97,505  \n",
       "6  ₹84,990  \n",
       "7  ₹85,990  \n",
       "8  ₹77,999  \n",
       "9  ₹87,800  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_laptop_info_amazon(url):\n",
    "    #intiating the browser\n",
    "    driver=webdriver.Chrome('C:/Users/yn/Desktop/Yuvi/DataTrained/seleniumWebdriver/chromedriver.exe')\n",
    "    #loading the given url\n",
    "    driver.get(url)\n",
    "    title_list=[]\n",
    "    rating_list=[]\n",
    "    price_list=[]\n",
    "    try:\n",
    "        #enter laptop in search keyword field  \n",
    "        driver.find_element_by_xpath('//input[@name=\"field-keywords\"]').send_keys('Laptop')\n",
    "        #click on search button\n",
    "        driver.find_element_by_id(\"nav-search-submit-button\").click()\n",
    "        #wait for few seconds\n",
    "        driver.implicitly_wait(30)\n",
    "        #refresh the driver web page\n",
    "        driver.refresh()\n",
    "        #select Intel core i7 as filter\n",
    "        driver.find_element_by_xpath('//li[@aria-label=\"Intel Core i7\"]//div[@class=\"a-checkbox a-checkbox-fancy s-navigation-checkbox aok-float-left\"]').click()\n",
    "        #click on search\n",
    "        #driver.find_element_by_xpath('//li[@aria-label=\"Intel Core i9\"]//input').click()\n",
    "        #wait for few seconds after clicking on search\n",
    "        driver.implicitly_wait(10)\n",
    "        #refresh the webpage as we get stale elements\n",
    "        driver.refresh()\n",
    "        # collect brand info \n",
    "        for title in driver.find_elements_by_xpath('//div[@data-component-type=\"s-search-result\"]//a[@class=\"a-link-normal a-text-normal\"]/span'):\n",
    "            title_list.append(title.text)\n",
    "\n",
    "        # collect prod description name\n",
    "        for rating in driver.find_elements_by_xpath('//a[@class=\"a-popover-trigger a-declarative\"]/ancestor::span[2]'):\n",
    "            rating_list.append(rating.get_attribute('aria-label'))\n",
    "\n",
    "        # collect price \n",
    "        for price in driver.find_elements_by_xpath('//div[@data-component-type=\"s-search-result\"]//span[@class=\"a-price\"]'):\n",
    "            price_list.append(price.text)\n",
    "           \n",
    "        #Create Dataframe using pandas\n",
    "        df=pd.DataFrame({'Title':title_list[:10],'Rating':rating_list[:10],'Price':price_list[:10]})\n",
    "        return df\n",
    "    finally:\n",
    "        #closing the browser window\n",
    "        driver.close()\n",
    "        #Quiting the .exe fill which is triggered to initiate the browser\n",
    "        driver.quit()\n",
    "        \n",
    "get_laptop_info_amazon('https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e1d02e",
   "metadata": {},
   "source": [
    "Q9: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida\n",
    "location. You have to scrape company name, No. of days ago when job was posted, Rating of the company.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the Job option as shown in the image \n",
    "3. After reaching to the next webpage, In place of “Search by Designations, Companies, Skills” enter\n",
    "“Data Scientist” and click on search button. \n",
    "4. You will reach to the following web page click on location and in place of “Search location” enter\n",
    "“Noida” and select location “Noida”. \n",
    "5. Then scrape the data for the first 10 jobs results you get on the above shown page.\n",
    "6. Finally create a dataframe of the scraped data.\n",
    "Note: All the steps required during scraping should be done through code only and not manually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b38e007e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CompanyName</th>\n",
       "      <th>No.of days posted ago</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LG Electronics India Pvt. Ltd.</td>\n",
       "      <td>7d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>14d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>14d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NTT Data Business Solutions Pvt Ltd</td>\n",
       "      <td>15d ago</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>16d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Paytm</td>\n",
       "      <td>20hr ago</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GI Group</td>\n",
       "      <td>9hr ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GI Group</td>\n",
       "      <td>9hr ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GI Group</td>\n",
       "      <td>9hr ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Steria India Ltd</td>\n",
       "      <td>1mon ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           CompanyName No.of days posted ago Rating\n",
       "0       LG Electronics India Pvt. Ltd.                7d ago    4.1\n",
       "1        GENPACT India Private Limited               14d ago    4.0\n",
       "2        GENPACT India Private Limited               14d ago    4.0\n",
       "3  NTT Data Business Solutions Pvt Ltd               15d ago    3.8\n",
       "4        GENPACT India Private Limited               16d ago    4.0\n",
       "5                                Paytm              20hr ago    3.7\n",
       "6                             GI Group               9hr ago    4.0\n",
       "7                             GI Group               9hr ago    4.0\n",
       "8                             GI Group               9hr ago    4.0\n",
       "9                     Steria India Ltd              1mon ago    4.1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_ambitionbox_info(url):\n",
    "    #intiating the browser\n",
    "    driver=webdriver.Chrome('C:/Users/yn/Desktop/Yuvi/DataTrained/seleniumWebdriver/chromedriver.exe')\n",
    "    #loading the given url\n",
    "    driver.get(url)\n",
    "    try:\n",
    "        #click on jobs\n",
    "        driver.find_element_by_xpath('//a[@title=\"Jobs\"]').click()\n",
    "        #Eneter data scientis\n",
    "        driver.find_element_by_xpath('//input[@title=\"Enter Designation, Company or a Skill\"]').send_keys('Data Scientist')\n",
    "        #click on search\n",
    "        driver.find_element_by_xpath('(//button[@class=\"ab_btn search-btn round\"])[1]').click()\n",
    "        #wait few seconds after clicking on search button\n",
    "        driver.implicitly_wait(20)\n",
    "        #click on location\n",
    "        driver.find_element_by_xpath('//div[@title=\"Location\"]/i').click()\n",
    "        #enter Noida in search bar\n",
    "        driver.find_element_by_xpath('//input[@placeholder=\"Search locations\"]').send_keys('Noida')\n",
    "        #select Noida button\n",
    "        driver.find_element_by_xpath('//input[@id=\"location_Noida\"]').click()\n",
    "        #waiting webdriver to load the page\n",
    "        time.sleep(3)\n",
    "\n",
    "        company_list=[] # empty list for company name\n",
    "        date_list=[] #empty list for posting date\n",
    "        rating_list=[] #empty list for ratings of company\n",
    "        \n",
    "        #collect company name\n",
    "        for comp in driver.find_elements_by_xpath('//div[@itemprop=\"itemListElement\"]//div[@class=\"company-info\"]/p'):\n",
    "            company_list.append(comp.text)\n",
    "            \n",
    "        #collect date posted ago\n",
    "        for date in driver.find_elements_by_xpath('//div[@itemprop=\"itemListElement\"]//div[@class=\"other-info\"]//span[1]'):\n",
    "            date_list.append(date.text)\n",
    "            \n",
    "        #collect rating\n",
    "        for rating in driver.find_elements_by_xpath('//div[@itemprop=\"itemListElement\"]//div[@class=\"company-info\"]//span'):\n",
    "            rating_list.append(rating.text)\n",
    "            \n",
    "        df=pd.DataFrame({'CompanyName':company_list[:10],'No.of days posted ago':date_list[:10],'Rating':rating_list[:10]})\n",
    "        return df\n",
    "    finally:\n",
    "        #closing the browser window\n",
    "        driver.close()\n",
    "        #Quiting the .exe fill which is triggered to initiate the browser\n",
    "        driver.quit()\n",
    "    \n",
    "get_ambitionbox_info('https://www.ambitionbox.com/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf4542d",
   "metadata": {},
   "source": [
    "Q10: Write a python program to scrape the salary data for Data Scientist designation.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary.\n",
    "The above task will be, done as shown in the below steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the salaries option as shown in the image. \n",
    "3. After reaching to the following webpage, In place of “Search Job Profile” enters “Data Scientist” and\n",
    "then click on “Data Scientist”. \n",
    "You have to scrape the data ticked in the above image.\n",
    "4. Scrape the data for the first 10 companies. Scrape the company name, total salary record, average\n",
    "salary, minimum salary, maximum salary, experience required.\n",
    "5. Store the data in a dataframe.\n",
    "Note: All the steps required during scraping should be done through code only and not manually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "489d22b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CompanyName</th>\n",
       "      <th>No.of Salary records</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Average Salary</th>\n",
       "      <th>Minimum Salary</th>\n",
       "      <th>Maximum Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ab Inbev</td>\n",
       "      <td>20 salaries</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "      <td>₹ 19.0L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 23.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZS</td>\n",
       "      <td>12 salaries</td>\n",
       "      <td>2 yrs exp</td>\n",
       "      <td>₹ 15.3L</td>\n",
       "      <td>₹ 9.8L</td>\n",
       "      <td>₹ 19.5L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Optum</td>\n",
       "      <td>23 salaries</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 21.3L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>66 salaries</td>\n",
       "      <td>2-4 yrs exp</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 9.5L</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UnitedHealth</td>\n",
       "      <td>47 salaries</td>\n",
       "      <td>2-4 yrs exp</td>\n",
       "      <td>₹ 13.5L</td>\n",
       "      <td>₹ 7.2L</td>\n",
       "      <td>₹ 20.5L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>26 salaries</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "      <td>₹ 13.5L</td>\n",
       "      <td>₹ 8.3L</td>\n",
       "      <td>₹ 18.5L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Verizon</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>4 yrs exp</td>\n",
       "      <td>₹ 12.7L</td>\n",
       "      <td>₹ 10.0L</td>\n",
       "      <td>₹ 21.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ganit Business Solutions</td>\n",
       "      <td>13 salaries</td>\n",
       "      <td>4 yrs exp</td>\n",
       "      <td>₹ 12.4L</td>\n",
       "      <td>₹ 8.5L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ericsson</td>\n",
       "      <td>42 salaries</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "      <td>₹ 11.7L</td>\n",
       "      <td>₹ 5.2L</td>\n",
       "      <td>₹ 21.5L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Deloitte</td>\n",
       "      <td>49 salaries</td>\n",
       "      <td>2-4 yrs exp</td>\n",
       "      <td>₹ 11.2L</td>\n",
       "      <td>₹ 6.8L</td>\n",
       "      <td>₹ 20.5L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                CompanyName No.of Salary records   Experience Average Salary  \\\n",
       "0                  Ab Inbev          20 salaries  3-4 yrs exp        ₹ 19.0L   \n",
       "1                        ZS          12 salaries    2 yrs exp        ₹ 15.3L   \n",
       "2                     Optum          23 salaries  3-4 yrs exp        ₹ 15.0L   \n",
       "3         Fractal Analytics          66 salaries  2-4 yrs exp        ₹ 15.0L   \n",
       "4              UnitedHealth          47 salaries  2-4 yrs exp        ₹ 13.5L   \n",
       "5           Tiger Analytics          26 salaries  3-4 yrs exp        ₹ 13.5L   \n",
       "6                   Verizon          14 salaries    4 yrs exp        ₹ 12.7L   \n",
       "7  Ganit Business Solutions          13 salaries    4 yrs exp        ₹ 12.4L   \n",
       "8                  Ericsson          42 salaries  3-4 yrs exp        ₹ 11.7L   \n",
       "9                  Deloitte          49 salaries  2-4 yrs exp        ₹ 11.2L   \n",
       "\n",
       "  Minimum Salary Maximum Salary  \n",
       "0        ₹ 15.0L        ₹ 23.0L  \n",
       "1         ₹ 9.8L        ₹ 19.5L  \n",
       "2        ₹ 11.0L        ₹ 21.3L  \n",
       "3         ₹ 9.5L        ₹ 22.0L  \n",
       "4         ₹ 7.2L        ₹ 20.5L  \n",
       "5         ₹ 8.3L        ₹ 18.5L  \n",
       "6        ₹ 10.0L        ₹ 21.0L  \n",
       "7         ₹ 8.5L        ₹ 15.0L  \n",
       "8         ₹ 5.2L        ₹ 21.5L  \n",
       "9         ₹ 6.8L        ₹ 20.5L  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_ambitionbox_salary_info(url):\n",
    "    #intiating the browser\n",
    "    driver=webdriver.Chrome('C:/Users/yn/Desktop/Yuvi/DataTrained/seleniumWebdriver/chromedriver.exe')\n",
    "    #loading the given url\n",
    "    driver.get(url)\n",
    "    try:\n",
    "        #click on salaries\n",
    "        driver.find_element_by_xpath('//a[@title=\"Company Salaries\"]').click()\n",
    "        driver.implicitly_wait(3)\n",
    "        #Eneter data scientist on search job profile bar\n",
    "        driver.find_element_by_xpath('//input[@id=\"jobProfileSearchbox\"]').send_keys('Data Scientist')\n",
    "        driver.implicitly_wait(3)\n",
    "        #click on Data Scientist\n",
    "        driver.find_element_by_xpath('(//div[@class=\"suggestion\"])[1]').click()\n",
    "        time.sleep(3)\n",
    "\n",
    "        company_list=[] # empty list for company name\n",
    "        salary_record=[]# empty list for salary recods\n",
    "        exp_list=[]# empty list for experience\n",
    "        avg_sal=[]# empty list for avg salry\n",
    "        min_sal=[]# empty list for min salary\n",
    "        max_sal=[]# empty list for max_salary\n",
    "    \n",
    "        #collect company name\n",
    "        for comp in driver.find_elements_by_xpath('//div[@class=\"results-body\"]//div[@class=\"company-info\"]//a'):\n",
    "            company_list.append(comp.text)\n",
    "       \n",
    "        #collect no of salary records\n",
    "        for sal_rec in driver.find_elements_by_xpath('//div[@class=\"results-body\"]//div[@class=\"company-info\"]/div[@class=\"name\"]/span'):\n",
    "            salary_record.append(sal_rec.text.replace('based on','').strip())\n",
    "          \n",
    "        #collect experience \n",
    "        for exp in driver.find_elements_by_xpath('//div[@class=\"salaries sbold-list-header\"]'):\n",
    "            exp_list.append(((exp.text)[exp.text.rindex('.')+1:]).strip())\n",
    "          \n",
    "        #collect Avg Salary \n",
    "        for avg in driver.find_elements_by_xpath('//p[@class=\"averageCtc\"]'):\n",
    "            avg_sal.append(avg.text)\n",
    "       \n",
    "        #collect min salary\n",
    "        for min_s in driver.find_elements_by_xpath('//div[@class=\"salary-values\"]/div[1]'):\n",
    "            min_sal.append(min_s.text)\n",
    "       \n",
    "        #collect max salary \n",
    "        for max_s in driver.find_elements_by_xpath('//div[@class=\"salary-values\"]/div[2]'):\n",
    "            max_sal.append(max_s.text)\n",
    "           \n",
    "        df=pd.DataFrame({'CompanyName':company_list[:10],'No.of Salary records':salary_record[:10],'Experience':exp_list[:10],'Average Salary':avg_sal[:10],'Minimum Salary':min_sal[:10],'Maximum Salary':max_sal[:10]})\n",
    "        return df\n",
    "    finally:\n",
    "        #closing the browser window\n",
    "        driver.close()\n",
    "        #Quiting the .exe fill which is triggered to initiate the browser\n",
    "        driver.quit()\n",
    "    \n",
    "get_ambitionbox_salary_info('https://www.ambitionbox.com/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
