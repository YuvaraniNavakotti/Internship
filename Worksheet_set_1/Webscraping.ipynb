{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c90ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import warnings\n",
    "import re\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50cee14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.Write a python program to display all the header tags from wikipedia.org.\n",
    "\n",
    "def get_header_tags(url):\n",
    "    page=requests.get(url,verify=False)\n",
    "    soup=BeautifulSoup(page.content)\n",
    "    return soup.find_all('h2',class_=\"mp-h2\")\n",
    "get_header_tags('https://en.wikipedia.org/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9aee76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release)\n",
    "#and make data frame.\n",
    "def get_imdb_top_100(url):\n",
    "    page=requests.get(url,verify=False)\n",
    "    soup=BeautifulSoup(page.content)\n",
    "    \n",
    "    title_list=[title.find('a').text for title in soup.find_all('h3',class_=\"lister-item-header\")]\n",
    "    \n",
    "    rating_list=[rating.find('span',class_=\"ipl-rating-star__rating\").text for rating in soup.find_all('div',class_=\"ipl-rating-star small\")]\n",
    "    \n",
    "    year_list=[year.text.replace('(','').replace(')','') for year in soup.find_all('span',class_=\"lister-item-year text-muted unbold\")]\n",
    "    \n",
    "    if(len(title_list)==len(rating_list)==len(year_list)):\n",
    "        df=pd.DataFrame({'Name':title_list,\"Rating\":rating_list,\"Year of Release\":year_list})\n",
    "        return df\n",
    "    else: return \"Element size should be same to form DataFrame\"\n",
    "        \n",
    "get_imdb_top_100('https://www.imdb.com/list/ls091520106/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e56ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3) Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of\n",
    "#release) and make data frame.\n",
    "def get_imdb_indian_top_100(url):\n",
    "    page=requests.get(url,verify=False)\n",
    "    soup=BeautifulSoup(page.content)\n",
    "\n",
    "    title_list=[title.find('a').text for title in soup.find_all('td',class_=\"titleColumn\")[:100]]\n",
    "  \n",
    "    rating_list=[rating.find('strong').text for rating in soup.find_all('td',class_=\"ratingColumn imdbRating\")[:100]]\n",
    "   \n",
    "    year_list=[year.text.replace('(','').replace(')','') for year in soup.find_all('span',class_=\"secondaryInfo\")[:100]]\n",
    "    \n",
    "    if(len(title_list)==len(year_list)==len(rating_list)):\n",
    "        df=pd.DataFrame({'Name':title_list,\"Rating\":rating_list,\"Year of Release\":year_list})\n",
    "        return df\n",
    "    return \"lenth of elements should be same to create a DataFrame\"\n",
    "get_imdb_indian_top_100('https://www.imdb.com/india/top-rated-indian-movies/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc6a082",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "\n",
    "#a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "def get_10_odi_teams(url):\n",
    "    page=requests.get(url,verify=False)\n",
    "    soup=BeautifulSoup(page.content)\n",
    "    table=soup.find('table',class_=\"table\")\n",
    "    tr_list=table.tbody.find_all('tr')[:10]\n",
    "    team_list=[]\n",
    "    matches_list=[]\n",
    "    points_list=[]\n",
    "    rating_list=[]\n",
    "    for tr in tr_list:\n",
    "        td_list=tr.find_all('td')\n",
    "        team_list.append(td_list[1].find('span',class_=\"u-hide-phablet\").text.replace('[','').replace(']',''))\n",
    "        matches_list.append(td_list[2].text)\n",
    "        points_list.append(td_list[3].text)\n",
    "        rating_list.append(td_list[4].text.replace('\\n','').strip())\n",
    "    if(len(team_list)==len(matches_list)==len(points_list)==len(rating_list)):\n",
    "        df=pd.DataFrame({'Teams':team_list,'Matches':matches_list,'Points':points_list,'Ratings':rating_list})\n",
    "        return df\n",
    "    else: return \"Element size should be same to form DataFrame\"\n",
    "get_10_odi_teams(\"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a61fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4)b) Top 10 ODI Batsmen in men along with the records of their team and rating.\n",
    "\n",
    "def get_10_odi_batsmen(url):\n",
    "    page=requests.get(url,verify=False)\n",
    "    soup=BeautifulSoup(page.content)\n",
    "    players_list=[]\n",
    "    rating_list=[]\n",
    "    team_list=[]\n",
    "    \n",
    "    main_div=soup.find('div',attrs={\"data-title\":\"ODI Batting Rankings\"},)\n",
    "    \n",
    "    sub_div=main_div.find('div',class_=\"rankings-block__banner\")   \n",
    "    \n",
    "    rating_list.append(sub_div.find('div',class_=\"rankings-block__banner--rating\").text)\n",
    "    \n",
    "    players_list.append(sub_div.find('div',class_=\"rankings-block__banner--name\").text)\n",
    "    \n",
    "    team_list.append(re.search(re.compile(r'(.*) (\\d+)'),sub_div.find('div',class_=\"rankings-block__banner--nationality\").text.replace('\\n','')).group(1).strip())\n",
    "    \n",
    "    table=main_div.find('table',class_=\"table rankings-card-table\")\n",
    "    \n",
    "    tr_list=table.tbody.find_all('tr')\n",
    "    \n",
    "    for tr in tr_list:\n",
    "        td_list=tr.find_all('td')       \n",
    "        players_list.append(td_list[1].find('a').text)        \n",
    "        team_list.append(td_list[2].find('span',class_=\"table-body__logo-text\").text)\n",
    "        rating_list.append(td_list[3].text.replace('\\n','').strip())\n",
    "        \n",
    "    if(len(players_list)==len(team_list)==len(rating_list)):\n",
    "        df=pd.DataFrame({'Players':players_list,'Teams':team_list,'Ratings':rating_list})\n",
    "        return df\n",
    "    else: return \"Element size should be same to form DataFrame\"\n",
    "get_10_odi_batsmen(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7db5e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4)c) Top 10 ODI bowlers along with the records of their team and rating.\n",
    "\n",
    "def get_10_odi_bowlers(url):\n",
    "    page=requests.get(url,verify=False)\n",
    "    soup=BeautifulSoup(page.content)\n",
    "    \n",
    "    players_list=[]\n",
    "    rating_list=[]\n",
    "    team_list=[]\n",
    "    \n",
    "    main_div=soup.find('div',attrs={\"data-title\":\"ODI Bowling Rankings\"})\n",
    "    \n",
    "    sub_div=main_div.find('div',class_=\"rankings-block__banner\")    \n",
    "\n",
    "    rating_list.append(sub_div.find('div',class_=\"rankings-block__banner--rating\").text)\n",
    "    \n",
    "    players_list.append(sub_div.find('div',class_=\"rankings-block__banner--name\").text)\n",
    "        \n",
    "    team_list.append(re.search(re.compile(r'(.*) (\\d+)'),sub_div.find('div',class_=\"rankings-block__banner--nationality\").text.replace('\\n','')).group(1).strip())\n",
    "    \n",
    "    table=main_div.find('table',class_=\"table rankings-card-table\")\n",
    "    \n",
    "    tr_list=table.tbody.find_all('tr')\n",
    "    \n",
    "    for tr in tr_list:\n",
    "        td_list=tr.find_all('td')       \n",
    "        players_list.append(td_list[1].find('a').text)        \n",
    "        team_list.append(td_list[2].find('span',class_=\"table-body__logo-text\").text)\n",
    "        rating_list.append(td_list[3].text.replace('\\n','').strip())\n",
    "        \n",
    "    if(len(players_list)==len(team_list)==len(rating_list)):\n",
    "        df=pd.DataFrame({'Players':players_list,'Teams':team_list,'Ratings':rating_list})\n",
    "        return df\n",
    "    else: return \"Element size should be same to form DataFrame\"\n",
    "get_10_odi_bowlers(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f30432",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "\n",
    "#a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "\n",
    "def get_10_odi_teams_womens(url):\n",
    "    page=requests.get(url,verify=False)\n",
    "    soup=BeautifulSoup(page.content)\n",
    "    table=soup.find('table',class_=\"table\")\n",
    "    tr_list=table.tbody.find_all('tr')[:10]\n",
    "    team_list=[]\n",
    "    matches_list=[]\n",
    "    points_list=[]\n",
    "    rating_list=[]\n",
    "    for tr in tr_list:\n",
    "        td_list=tr.find_all('td')\n",
    "        team_list.append(td_list[1].find('span',class_=\"u-hide-phablet\").text.replace('[','').replace(']',''))\n",
    "        matches_list.append(td_list[2].text)\n",
    "        points_list.append(td_list[3].text)\n",
    "        rating_list.append(td_list[4].text.replace('\\n','').strip())\n",
    "    if(len(team_list)==len(matches_list)==len(points_list)==len(rating_list)):\n",
    "        df=pd.DataFrame({'Teams':team_list,'Matches':matches_list,'Points':points_list,'Ratings':rating_list})\n",
    "        return df\n",
    "    else: return \"Element size should be same to form DataFrame\"\n",
    "get_10_odi_teams_womens(\"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45d52d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5)b) Top 10 women’s ODI players along with the records of their team and rating.\n",
    "def get_10_odi_women_players(url):\n",
    "    page=requests.get(url,verify=False)\n",
    "    soup=BeautifulSoup(page.content)\n",
    "    players_list=[]\n",
    "    rating_list=[]\n",
    "    team_list=[]\n",
    "    \n",
    "    main_div=soup.find('div',attrs={\"data-title\":\"ODI Batting Rankings\"},)\n",
    "    \n",
    "    sub_div=main_div.find('div',class_=\"rankings-block__banner\")\n",
    "     \n",
    "    rating_list.append(sub_div.find('div',class_=\"rankings-block__banner--rating\").text)\n",
    " \n",
    "    players_list.append(sub_div.find('div',class_=\"rankings-block__banner--name\").text)\n",
    "    \n",
    "    team_list.append(re.search(re.compile(r'(.*) (\\d+)'),sub_div.find('div',class_=\"rankings-block__banner--nationality\").text.replace('\\n','')).group(1).strip())\n",
    "    \n",
    "    table=main_div.find('table',class_=\"table rankings-card-table\")\n",
    "    \n",
    "    tr_list=table.tbody.find_all('tr')\n",
    "    \n",
    "    for tr in tr_list:\n",
    "        td_list=tr.find_all('td')       \n",
    "        players_list.append(td_list[1].find('a').text)        \n",
    "        team_list.append(td_list[2].find('span',class_=\"table-body__logo-text\").text)\n",
    "        rating_list.append(td_list[3].text.replace('\\n','').strip())\n",
    "        \n",
    "    if(len(players_list)==len(team_list)==len(rating_list)):\n",
    "        df=pd.DataFrame({'Players':players_list,'Teams':team_list,'Ratings':rating_list})\n",
    "        return df\n",
    "    else: return \"Element size should be same to form DataFrame\"\n",
    "    \n",
    "get_10_odi_women_players(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a74e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5)c) Top 10 women’s ODI all-rounder along with the records of their team and rating.\n",
    "\n",
    "def get_10_odi_women_all_rounder(url):\n",
    "    page=requests.get(url,verify=False)\n",
    "    soup=BeautifulSoup(page.content)\n",
    "    players_list=[]\n",
    "    rating_list=[]\n",
    "    team_list=[]\n",
    "    \n",
    "    main_div=soup.find('div',attrs={\"data-title\":\"ODI All-Rounder Rankings\"})\n",
    "    \n",
    "    sub_div=main_div.find('div',class_=\"rankings-block__banner\")\n",
    "    \n",
    "    rating_list.append(sub_div.find('div',class_=\"rankings-block__banner--rating\").text)\n",
    "\n",
    "    players_list.append(sub_div.find('div',class_=\"rankings-block__banner--name\").text)\n",
    "\n",
    "    team_list.append(re.search(re.compile(r'(.*) (\\d+)'),sub_div.find('div',class_=\"rankings-block__banner--nationality\").text.replace('\\n','')).group(1).strip())\n",
    "    \n",
    "    table=main_div.find('table',class_=\"table rankings-card-table\")\n",
    "    \n",
    "    tr_list=table.tbody.find_all('tr')\n",
    "    \n",
    "    for tr in tr_list:\n",
    "        td_list=tr.find_all('td')       \n",
    "        players_list.append(td_list[1].find('a').text)        \n",
    "        team_list.append(td_list[2].find('span',class_=\"table-body__logo-text\").text)\n",
    "        rating_list.append(td_list[3].text.replace('\\n','').strip())\n",
    "        \n",
    "    if(len(players_list)==len(team_list)==len(rating_list)):\n",
    "        df=pd.DataFrame({'Players':players_list,'Teams':team_list,'Ratings':rating_list})\n",
    "        return df\n",
    "    else: return \"Element size should be same to form DataFrame\"\n",
    "    \n",
    "get_10_odi_women_all_rounder(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97c8043",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6) Write a python program to scrape details of all the posts from coreyms.com. Scrape the heading, date, content\n",
    "#and the code for the video from the link for the youtube video from the post.\n",
    "\n",
    "def all_posts(url):\n",
    "    page=requests.get(url,verify=False)\n",
    "    soup=BeautifulSoup(page.content)\n",
    "\n",
    "    headers=[header.text for header in soup.find_all('a',class_=\"entry-title-link\")]\n",
    "\n",
    "    dates=[date.text for date in soup.find_all('time',class_=\"entry-time\")]\n",
    "\n",
    "    contents=[content.p.text for content in soup.find_all('div',class_=\"entry-content\")]\n",
    "    \n",
    "    links=[link.get('src') for link in soup.find_all('iframe',class_=\"youtube-player\")]   \n",
    "    print(\"Headers\")\n",
    "    print(headers)\n",
    "    print(\"===============================================\")\n",
    "    print(\"Dates\")\n",
    "    print(dates)\n",
    "    print(\"===============================================\")\n",
    "    print(\"Links\")\n",
    "    print(links)\n",
    "        \n",
    "all_posts(\"https://coreyms.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f60f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7) Write a python program to scrape house details from mentioned URL. It should include house title, location,\n",
    "#area, EMI and price from nobroker.in.\n",
    "\n",
    "def house_details(url):\n",
    "    page=requests.get(url,verify=False)\n",
    "    soup=BeautifulSoup(page.content)    \n",
    "    house_names=[name.find('span').text for name in soup.find_all('h2',class_=\"heading-6 font-semi-bold nb__25Cl7\")]\n",
    "    \n",
    "    locations_list=[location.text for location in soup.find_all('div',class_=\"nb__1EwQz\")]\n",
    "        \n",
    "    area_list=[area.text for area in soup.find_all('div',class_=\"nb__FfHqA\")]\n",
    "    \n",
    "    emi_list=[emi.text for emi in soup.find_all('div',attrs={\"id\":\"roomType\"})]\n",
    "        \n",
    "    price_list=[price.nextSibling.text.replace('[','').replace(']','') for price in soup.find_all('meta',attrs={\"content\":\"Minimum Deposit\"})]\n",
    "    \n",
    "    if((len(price_list)==len(house_names)==len(locations_list)==len(area_list)==len(emi_list))):\n",
    "        df=pd.DataFrame({\"HouseName\":house_names,\"Location\":locations_list,\"Area\":area_list,\"EMI\":emi_list,\"Price\":price_list})\n",
    "        return df\n",
    "    else: return \"Element size should be same to form DataFrame\"\n",
    "        \n",
    "house_details(\"https://www.nobroker.in/property/sale/bangalore/Electronic%20City?type=BHK4&searchParam=W3sibGF0IjoxMi44N%20DUyMTQ1LCJsb24iOjc3LjY2MDE2OTUsInBsYWNlSWQiOiJDaElKdy1GUWQ0cHNyanNSSGZkYXpnXzhYRW8%20iLCJwbGFjZU5hbWUiOiJFbGVjdHJvbmljIENpdHkifV0=&propertyAge=0&radius=2.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b489c440",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8) Write a python program to scrape mentioned details from dineout.co.in :\n",
    "#i) Restaurant name\n",
    "#ii) Cuisine\n",
    "#iii) Location\n",
    "#iv) Ratings\n",
    "#v) Image URL\n",
    "\n",
    "def dineout_details(url):\n",
    "    page=requests.get(url,verify=False)\n",
    "    soup=BeautifulSoup(page.content)    \n",
    "    rest_names=[name.text for name in soup.find_all('a',class_=\"restnt-name ellipsis\")]\n",
    "    \n",
    "    locations_list=[location.text for location in soup.find_all('div',class_=\"restnt-loc ellipsis\")]\n",
    "        \n",
    "    ratings_list=[rating.text for rating in soup.find_all('div',class_=\"restnt-rating rating-4\")]\n",
    "    \n",
    "    img_list=[img.get('data-src') for img in soup.find_all('img',class_=\"no-img\")]\n",
    "        \n",
    "    cuisines_list=[cuisine.text[cuisine.text.rfind('|')+1:] for cuisine in soup.find_all('span',class_=\"double-line-ellipsis\")]\n",
    "    \n",
    "    if((len(rest_names)==len(locations_list)==len(ratings_list)==len(img_list)==len(cuisines_list))):\n",
    "        df=pd.DataFrame({\"Restaurant Names\":rest_names,\"Cuisines\":cuisines_list,\"Location\":locations_list,\"Rating\":ratings_list,\"Img Url\":img_list})\n",
    "        return df\n",
    "    else: return \"Element size should be same to form DataFrame\"\n",
    "        \n",
    "dineout_details(\"https://www.dineout.co.in/delhi-restaurants/buffet-special\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202cbd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9) Write a python program to scrape weather details for last 24 hours from Tutiempo.net :\n",
    "#i) Hour\n",
    "#ii) Temperature\n",
    "#iii) Wind\n",
    "#iv) Weather condition\n",
    "#v) Humidity\n",
    "#vi) Pressure\n",
    "\n",
    "def weather_details(url):\n",
    "    page=requests.get(url,verify=False)\n",
    "    soup=BeautifulSoup(page.content) \n",
    "    \n",
    "    table=soup.find('div',class_=\"last24 thh\").table\n",
    "    hours=[]\n",
    "    temperature=[]\n",
    "    wind=[]\n",
    "    weather=[]\n",
    "    humidity=[]\n",
    "    pressure=[]\n",
    "    \n",
    "    for tr in table.tbody.find_all('tr')[2:]:\n",
    "        td_list=tr.find_all('td')\n",
    "        if(len(td_list)!=0):\n",
    "            hours.append(td_list[0].text)\n",
    "            temperature.append(td_list[2].text)\n",
    "            wind.append(td_list[3].text)\n",
    "            weather.append(td_list[1].text)\n",
    "            humidity.append(td_list[4].text)\n",
    "            pressure.append(td_list[5].text)\n",
    "    \n",
    "    if((len(hours)==len(temperature)==len(wind)==len(weather)==len(humidity)==len(pressure))):\n",
    "        df=pd.DataFrame({\"Hour\":hours,\"Temprature\":temperature,\"Wind\":wind,\"Weather\":weather,\"Humidity\":humidity,\"pressure\":pressure})\n",
    "        return df\n",
    "    else: return \"Element size should be same to form DataFrame\"\n",
    "        \n",
    "weather_details(\"https://en.tutiempo.net/delhi.html?data=last-24-hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c359dc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10).Write a python program to scrape monument name, monument description, image URL about top 10 monuments\n",
    "#from puredestinations.co.uk.\n",
    "\n",
    "def monument_details(url):\n",
    "    page=requests.get(url,verify=False)\n",
    "    soup=BeautifulSoup(page.content)  \n",
    "    \n",
    "    p_tagse=soup.find('h3',class_=\"title title--heading\").parent.find_all('p')\n",
    "    \n",
    "    monument_names=[p.find('strong').text for p in p_tagse if p.find('strong')!=None][:10]\n",
    "    \n",
    "    monument_desc=[p.find('strong').parent.find_next_sibling('p').text for p in p_tagse if p.find('strong')!=None][:10]\n",
    "\n",
    "    monument_url=[p.find('img').get('data-src').replace('http:','https:') for p in p_tagse if p.find('img')!=None][:10]\n",
    "    \n",
    "    if((len(monument_names)==len(monument_desc)==len(monument_url))):\n",
    "        df=pd.DataFrame({\"Monument Names\":monument_names,\"Monument Description\":monument_desc,\"Monument IMG Url\":monument_url})\n",
    "        return df\n",
    "    else: return \"Element size should be same to form DataFrame\" \n",
    "        \n",
    "monument_details(\"https://www.puredestinations.co.uk/top-10-famous-monuments-to-visit-in-india/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c02e135",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b36257b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
